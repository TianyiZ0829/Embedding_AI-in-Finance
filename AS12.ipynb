{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS12\n",
    "## Tianyi Zhu\n",
    "#### Citation: Code structures and functions are get help from Chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhutianyi/Desktop/OneDrive - Georgia Institute of Technology/24 Fall/AI/AS12\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16aa8ab90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_file = \"sample_company.csv\"\n",
    "description_zip = \"business_description_10K.zip\"\n",
    "msf_file = \"MSF_1996_2023.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction successful!\n",
      "Extracted Files: ['10K_item1_PERMNO']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the path of the zip file and the extraction directory\n",
    "zip_file = \"business_description_10K.zip\"\n",
    "extraction_path = \"business_description_10K\"\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extraction_path, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    shutil.unpack_archive(zip_file, extraction_path)\n",
    "    print(\"Extraction successful!\")\n",
    "\n",
    "    # List the first few files to verify extraction\n",
    "    extracted_files = os.listdir(extraction_path)\n",
    "    print(\"Extracted Files:\", extracted_files[:5])\n",
    "except Exception as e:\n",
    "    print(\"Extraction failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Company Data:\n",
      "   label  year                                             PERMNO\n",
      "0      0  1996  [11614, 76862, 77056, 82225, 20598, 16468, 762...\n",
      "1      0  1997  [12006, 67619, 54981, 16468, 84422, 85213, 116...\n",
      "2      0  1998  [20598, 76950, 77730, 76264, 85982, 84422, 117...\n",
      "3      0  1999  [77730, 85037, 85982, 85951, 77099, 51190, 839...\n",
      "4      0  2000  [85213, 85982, 87021, 12282, 77099, 11614, 164...\n",
      "MSF Data:\n",
      "   PERMNO        date  SHRCD SICCD TICKER           COMNAM  PERMCO     CUSIP  \\\n",
      "0   10001  1996-01-31     11  4920   EWST  ENERGY WEST INC    7953  36720410   \n",
      "1   10001  1996-02-29     11  4920   EWST  ENERGY WEST INC    7953  36720410   \n",
      "2   10001  1996-03-29     11  4920   EWST  ENERGY WEST INC    7953  36720410   \n",
      "3   10001  1996-04-30     11  4920   EWST  ENERGY WEST INC    7953  36720410   \n",
      "4   10001  1996-05-31     11  4920   EWST  ENERGY WEST INC    7953  36720410   \n",
      "\n",
      "   BIDLO  ASKHI      PRC    VOL        RET    BID   ASK  SHROUT       RETX  \\\n",
      "0  8.750  9.500 -9.12500  168.0  -0.026667  8.750  9.50  2281.0  -0.026667   \n",
      "1  8.750  9.500  9.25000  524.0   0.013699  9.250  9.75  2281.0   0.013699   \n",
      "2  9.250  9.750  9.48438  283.0   0.036149  9.000  9.50  2309.0   0.025338   \n",
      "3  8.625  9.375 -8.81250  327.0  -0.070840  8.625  9.00  2309.0  -0.070840   \n",
      "4  8.625  9.000  8.62500  103.0  -0.021277  8.625  9.00  2309.0  -0.021277   \n",
      "\n",
      "     vwretd  \n",
      "0  0.028121  \n",
      "1  0.016353  \n",
      "2  0.010914  \n",
      "3  0.025560  \n",
      "4  0.026810  \n"
     ]
    }
   ],
   "source": [
    "# Load sample_company.csv\n",
    "sample_df = pd.read_csv(company_file)\n",
    "print(\"Sample Company Data:\")\n",
    "print(sample_df.head())\n",
    "\n",
    "# Load MSF data\n",
    "msf_df = pd.read_csv(msf_file)\n",
    "print(\"MSF Data:\")\n",
    "print(msf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON files: 100%|██████████| 110294/110294 [00:39<00:00, 2795.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store data\n",
    "business_data = []\n",
    "\n",
    "json_dir = \"business_description_10K/10K_item1_PERMNO\"\n",
    "\n",
    "# Loop through each JSON file in the directory\n",
    "for file_name in tqdm(os.listdir(json_dir), desc=\"Reading JSON files\"):\n",
    "    if file_name.endswith('.json'):\n",
    "        file_path = os.path.join(json_dir, file_name)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "                # Extract the relevant information\n",
    "                permno = data.get(\"PERMNO\", None)\n",
    "                filing_date = data.get(\"filing_date\", None)\n",
    "                description = data.get(\"item_1\", \"\") \n",
    "                \n",
    "                # Append the data to the list\n",
    "                business_data.append({\n",
    "                    \"PERMNO\": permno,\n",
    "                    \"filing_date\": filing_date,\n",
    "                    \"description\": description\n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {file_name}. Skipping.\")\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "business_df = pd.DataFrame(business_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Business Data:\n",
      "   PERMNO filing_date                                        description\n",
      "0   89526  2003-03-28  A. General Development of Business First Natio...\n",
      "1   82587  2020-02-12  Overview Intevac’s business consists of two re...\n",
      "2   12380  2009-09-24  Summary of Business Park City Group, Inc. (the...\n",
      "3   90024  2006-04-14  . General We are a national, mall-based, speci...\n",
      "4   76732  2021-03-02  Dine Brands Global, Inc.SM, together with its ...\n"
     ]
    }
   ],
   "source": [
    "# Function to clean the business description text\n",
    "def clean_description(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove the \"ITEM 1. BUSINESS\" header (case insensitive)\n",
    "    text = re.sub(r'item\\s*1[\\.:]?\\s*business', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove extra new lines and whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the description column\n",
    "business_df['description'] = business_df['description'].apply(clean_description)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned Business Data:\")\n",
    "print(business_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89526</td>\n",
       "      <td>2003-03-28</td>\n",
       "      <td>A. General Development of Business First Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82587</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>Overview Intevac’s business consists of two re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12380</td>\n",
       "      <td>2009-09-24</td>\n",
       "      <td>Summary of Business Park City Group, Inc. (the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90024</td>\n",
       "      <td>2006-04-14</td>\n",
       "      <td>. General We are a national, mall-based, speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76732</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Dine Brands Global, Inc.SM, together with its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110289</th>\n",
       "      <td>87236</td>\n",
       "      <td>2000-03-22</td>\n",
       "      <td>. OVERVIEW InterNAP Network Services Corporati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110290</th>\n",
       "      <td>84331</td>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>BUSINESS GENERAL River Valley Bancorp (the “Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110291</th>\n",
       "      <td>77652</td>\n",
       "      <td>1996-09-17</td>\n",
       "      <td>. The Rival Company, the registrant, together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110292</th>\n",
       "      <td>86248</td>\n",
       "      <td>2008-09-29</td>\n",
       "      <td>Overview In this Annual Report on Form 10-K, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110293</th>\n",
       "      <td>17327</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>. Overview One Stop Systems (OSS) designs, man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PERMNO filing_date                                        description\n",
       "0        89526  2003-03-28  A. General Development of Business First Natio...\n",
       "1        82587  2020-02-12  Overview Intevac’s business consists of two re...\n",
       "2        12380  2009-09-24  Summary of Business Park City Group, Inc. (the...\n",
       "3        90024  2006-04-14  . General We are a national, mall-based, speci...\n",
       "4        76732  2021-03-02  Dine Brands Global, Inc.SM, together with its ...\n",
       "...        ...         ...                                                ...\n",
       "110289   87236  2000-03-22  . OVERVIEW InterNAP Network Services Corporati...\n",
       "110290   84331  2014-03-18  BUSINESS GENERAL River Valley Bancorp (the “Ho...\n",
       "110291   77652  1996-09-17  . The Rival Company, the registrant, together ...\n",
       "110292   86248  2008-09-29  Overview In this Annual Report on Form 10-K, w...\n",
       "110293   17327  2018-03-21  . Overview One Stop Systems (OSS) designs, man...\n",
       "\n",
       "[110294 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.to_csv('business_des.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df['year'] = pd.to_datetime(business_df['filing_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>PERMNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>[11614, 76862, 77056, 82225, 20598, 16468, 762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>[12006, 67619, 54981, 16468, 84422, 85213, 116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>[20598, 76950, 77730, 76264, 85982, 84422, 117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>[77730, 85037, 85982, 85951, 77099, 51190, 839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>[85213, 85982, 87021, 12282, 77099, 11614, 164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>[14675, 16181, 14312, 19024, 15902, 14792, 187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>[17868, 17034, 15272, 17958, 17122, 16308, 137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>[20344, 14422, 21708, 20614, 15417, 16974, 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>[20640, 18205, 14451, 20341, 21842, 19135, 184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "      <td>[20062, 15543, 17818, 21281, 17134, 21735, 182...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  year                                             PERMNO\n",
       "0        0  1996  [11614, 76862, 77056, 82225, 20598, 16468, 762...\n",
       "1        0  1997  [12006, 67619, 54981, 16468, 84422, 85213, 116...\n",
       "2        0  1998  [20598, 76950, 77730, 76264, 85982, 84422, 117...\n",
       "3        0  1999  [77730, 85037, 85982, 85951, 77099, 51190, 839...\n",
       "4        0  2000  [85213, 85982, 87021, 12282, 77099, 11614, 164...\n",
       "..     ...   ...                                                ...\n",
       "275      9  2019  [14675, 16181, 14312, 19024, 15902, 14792, 187...\n",
       "276      9  2020  [17868, 17034, 15272, 17958, 17122, 16308, 137...\n",
       "277      9  2021  [20344, 14422, 21708, 20614, 15417, 16974, 155...\n",
       "278      9  2022  [20640, 18205, 14451, 20341, 21842, 19135, 184...\n",
       "279      9  2023  [20062, 15543, 17818, 21281, 17134, 21735, 182...\n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_company_path = 'sample_company.csv'\n",
    "sample_df = pd.read_csv(sample_company_path)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "sample_df['PERMNO'] = sample_df['PERMNO'].apply(ast.literal_eval)\n",
    "\n",
    "sample_df = sample_df.explode('PERMNO')\n",
    "sample_df['PERMNO'] = pd.to_numeric(sample_df['PERMNO'], errors='coerce')\n",
    "\n",
    "sample_df.dropna(subset=['PERMNO', 'year'], inplace=True)\n",
    "sample_df['PERMNO'] = sample_df['PERMNO'].astype(int)\n",
    "sample_df['year'] = sample_df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75517</td>\n",
       "      <td>2003-03-28</td>\n",
       "      <td>General Development of Business Marten Transpo...</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79824</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>General First Financial Bankshares, Inc., a Te...</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82746</td>\n",
       "      <td>1999-03-25</td>\n",
       "      <td>Overview Synaptic Pharmaceutical Corporation (...</td>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33420</td>\n",
       "      <td>1999-03-29</td>\n",
       "      <td>GENERAL DEVELOPMENT OF BUSINESS Equity Oil Com...</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76950</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>Company Background We design, market, and dist...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>11955</td>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>. GENERAL USA Waste Services, Inc. (\"USA Waste...</td>\n",
       "      <td>1998</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>20598</td>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>Our Business Cal-Maine Foods, Inc. (“we,” “us,...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>78963</td>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>Overview Chico’s FAS, Inc.1, is a cultivator o...</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>90238</td>\n",
       "      <td>2013-03-15</td>\n",
       "      <td>Overview We are a leading company using propri...</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>89400</td>\n",
       "      <td>2005-12-12</td>\n",
       "      <td>. General We are a leading provider of integra...</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERMNO filing_date                                        description  \\\n",
       "0      75517  2003-03-28  General Development of Business Marten Transpo...   \n",
       "1      79824  2021-02-22  General First Financial Bankshares, Inc., a Te...   \n",
       "2      82746  1999-03-25  Overview Synaptic Pharmaceutical Corporation (...   \n",
       "3      33420  1999-03-29  GENERAL DEVELOPMENT OF BUSINESS Equity Oil Com...   \n",
       "4      76950  2014-02-26  Company Background We design, market, and dist...   \n",
       "...      ...         ...                                                ...   \n",
       "1936   11955  1998-03-31  . GENERAL USA Waste Services, Inc. (\"USA Waste...   \n",
       "1937   20598  2014-07-28  Our Business Cal-Maine Foods, Inc. (“we,” “us,...   \n",
       "1938   78963  2015-03-09  Overview Chico’s FAS, Inc.1, is a cultivator o...   \n",
       "1939   90238  2013-03-15  Overview We are a leading company using propri...   \n",
       "1940   89400  2005-12-12  . General We are a leading provider of integra...   \n",
       "\n",
       "      year  label  \n",
       "0     2003      4  \n",
       "1     2021      7  \n",
       "2     1999      9  \n",
       "3     1999      1  \n",
       "4     2014      0  \n",
       "...    ...    ...  \n",
       "1936  1998      9  \n",
       "1937  2014      0  \n",
       "1938  2015      6  \n",
       "1939  2013      8  \n",
       "1940  2005      3  \n",
       "\n",
       "[1941 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(business_df, sample_df[['PERMNO', 'year', 'label']], on=['PERMNO', 'year'], how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize business description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized data keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "Example input_ids: tensor([[  101,  2236,  2458,  1997,  2449, 20481,  2368,  3665,  1010,  5183,\n",
      "          1012,  2003,  1037,  2146,  1011, 14655,  4744, 11066,  6839,  4346,\n",
      "          9474,  2326,  5193,  1998,  2051,  1011,  7591,  5193,  1012,  1523,\n",
      "          9474,  2326,  5193,  1524,  2965,  4860,  4758,  2030, 16021,  8898,\n",
      "          9118,  1997,  4860,  1011,  7591,  4475,  1998,  2236, 21955,  1012,\n",
      "          2057,  2031,  4082,  3691,  1010,  2119,  3206,  1998,  2691,  1010,\n",
      "          4379,  2011,  1996,  7553,  6236,  3222,  1010,  2030, 16461,  1010,\n",
      "          1998,  2024,  2747, 12222,  2011,  1996,  2142,  2163,  2533,  1997,\n",
      "          5193,  1010,  2030, 11089,  1010,  1998,  1996,  2976,  3307,  3447,\n",
      "          1010,  2030,  1042, 18663,  1012,  2004,  1997,  2285,  2861,  1010,\n",
      "          2526,  1010,  2057,  3498,  1037,  4170,  1997,  1016,  1010,  5718,\n",
      "          2620, 28292,  1998,  1016,  1010,  6163,  2575, 21389,  1012,  2087,\n",
      "          1997,  2256, 21389,  2024,  6055,  2007, 25416,  3089,  4590,  3370,\n",
      "          3197,  1012,  2004,  1997,  2285,  2861,  1010,  2526,  1010,  1015,\n",
      "          1010,  4805,  2581, 28292,  1998,  1016,  1010,  5764,  2575, 21389,\n",
      "          1999,  2256,  4170,  2020,  2194,  1011,  3079,  1998,  6079,  2487,\n",
      "         28292,  1998,  2184, 21389,  2020,  2104,  3206,  2007,  2981, 16728,\n",
      "          1012,  2004,  1997,  2285,  2861,  1010,  2526,  1010,  2057,  2018,\n",
      "          1015,  1010,  6109,  2575,  5126,  1010,  2164,  1015,  1010,  4583,\n",
      "          2549,  6853,  1012,  2076,  1996,  2627,  2274,  2086,  2256,  2449,\n",
      "          2038,  4961, 12381,  1012,  2011,  2126,  1997,  7831,  1010,  2004,\n",
      "          1997,  2285,  2861,  1010,  2722,  1010,  2057,  3498,  1037,  4170,\n",
      "          1997,  1015,  1010, 26628, 28292,  1998,  1015,  1010,  6640,  2629,\n",
      "         21389,  1010,  1998,  2057,  2018,  1015,  1010, 23688,  5126,  1010,\n",
      "          2164,  5345,  2487,  6853,  1012,  2256,  5126,  2024,  2025,  3421,\n",
      "          2011,  1037,  7268, 21990,  3131,  1012,  4114,  2104,  5273,  2375,\n",
      "          1999,  3359,  1010,  2057,  2024,  1037,  6332,  2000,  1037,  7082,\n",
      "         21584,  9650,  5074,  1054,  1012, 20481,  2368,  2631,  1999,  3918,\n",
      "          1012,  1999,  2997,  1010,  2057, 27788, 24586,  6525,  3064,  2104,\n",
      "          8452,  2375,  1012,  2256,  3237,  4822,  2024,  2284,  2012, 14378,\n",
      "         20481,  2368,  2395,  1010, 12256,  3527,  5737,  1010,  5273,  5139,\n",
      "         23352,  2629,  1012,  2256,  7026,  2193,  2003,  1006,  6390,  2629,\n",
      "          1007,  6227,  2575,  1011, 29403,  2575,  1012,  3361,  2592,  2055,\n",
      "          9214,  2144,  2256, 12149,  1010,  2256,  6599,  1010,  4082, 11372,\n",
      "          1998,  7045,  2031,  3141,  2000,  2028,  2449,  6903,  1011,  2146,\n",
      "          1011, 14655,  4744, 11066,  9118,  4346,  9474,  2326,  5193,  1998,\n",
      "          2051,  1011,  7591,  5193,  1012,  7984,  6412,  1997,  2449,  2057,\n",
      "          2569,  4697,  1999,  9474,  2326,  5193,  1997,  9440,  1998,  2060,\n",
      "          3688,  9034,  4860,  1011,  4758,  9118,  2030, 16021,  8898,  9118,\n",
      "          1010,  1998,  2057, 13566,  2000,  3613, 14055,  1999,  2023,  4054,\n",
      "          2326,  1012,  2057,  2036,  3073,  4318,  8441,  9118,  1012,  1999,\n",
      "          2526,  1010,  2057,  3687,  6282,  3867,  1997,  2256,  6599,  2013,\n",
      "         23113,  9474,  2326,  3688,  1998,  2539,  3867,  1997,  2256,  6599,\n",
      "          2013, 23113,  4318,  8441,  1012,  2256,  3078,  4026, 10914,  2024,\n",
      "          2090,  1996, 13608,  1998,  1996,  2225,  3023,  1010,  4943,  1010,\n",
      "          4643,  1998,  1996,  2264,  3023,  1010,  2004,  2092,  2004,  2013,\n",
      "          2662,  2000,  1996,  3534,  4514,  1012,  2087,  1997,  2256,  4318,\n",
      "          8441, 15665,  5478,  1996,  2569,  2578,  2057,  3749,  2030,  3499,\n",
      "          2149,  2000,  2597,  2256,  3941,  2005, 23113,  9474,  2326, 15665,\n",
      "          1012,  1996,  7772,  5193,  2578,  2057,  3749,  2421,  1024,  1528,\n",
      "         12530,  3085,  1010,  2397,  1011,  2944, 28292,  4352, 23259, 23534,\n",
      "          1025,   102]])\n",
      "Example attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "# Define tokenizer settings\n",
    "tokenizer_settings = {\n",
    "    'truncation': True,\n",
    "    'padding': 'max_length',\n",
    "    'max_length': 512,\n",
    "    'add_special_tokens': True,\n",
    "    'return_attention_mask': True,\n",
    "    'return_tensors': 'pt'\n",
    "}\n",
    "\n",
    "# Tokenize the business descriptions\n",
    "descriptions = merged_df['description'].tolist()\n",
    "tokenized_data = tokenizer(descriptions, **tokenizer_settings)\n",
    "\n",
    "# Display the tokenized output example\n",
    "print(\"Tokenized data keys:\", tokenized_data.keys())\n",
    "print(\"Example input_ids:\", tokenized_data['input_ids'][:1])\n",
    "print(\"Example attention_mask:\", tokenized_data['attention_mask'][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1552\n",
      "Validation set size: 194\n",
      "Test set size: 195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the merged DataFrame into train, validation, and test sets (80%, 10%, 10%)\n",
    "train_df, temp_df = train_test_split(merged_df, test_size=0.2, random_state=42, stratify=merged_df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "# Display the sizes of each split\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fine-tunning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhutianyi/anaconda3/envs/new_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=10, \n",
    "    output_hidden_states=True  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
